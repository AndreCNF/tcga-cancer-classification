{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models dummy tests\n",
    "\n",
    "Testing models from the project defined classes, including the embedding layers and time intervals handling, on dummy datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                        # Pandas to load the data initially\n",
    "import numpy as np                         # Mathematical operations package, allowing also for missing values representation\n",
    "import torch                               # PyTorch for tensor and deep learning operations\n",
    "import data_utils as du                    # Data science and machine learning relevant methods\n",
    "import os                                  # os handles directory/workspace changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.use_modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.set_pandas_library('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "du.use_modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pixiedust                           # Debugging in Jupyter Notebook cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to scripts directory\n",
    "os.chdir('../../scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tabular_Dataset import Tabular_Dataset # Dataset class that helps fetching batches of data\n",
    "import Models                              # Script with all the machine learning model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to parent directory (presumably \"eICU-mortality-prediction\")\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data that we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "dmy_data = np.array([[0, 23, 284, 70, 5, np.nan, 0],\n",
    "                     [91, 23, 284, 70, 5, 'b', 0],\n",
    "                     [92, 24, 270, 73, 5, 'b', 0],\n",
    "                     [93, 22, 290, 71, 5, 'a', 0],\n",
    "                     [93, 22, 290, 71, 5, 'b', 0],\n",
    "                     [94, 20, 288, 65, 4, 'a', 1],\n",
    "                     [94, 20, 288, 65, 4, 'b', 1],\n",
    "                     [95, 21, 297, 64, 4, 'a', 1],\n",
    "                     [95, 21, 297, 64, 4, 'b', 1],\n",
    "                     [95, 21, 297, 64, 4, 'c', 1],\n",
    "                     [10, 25, 300, 76, 5, 'a', 0],\n",
    "                     [11, 19, 283, 70, 5, 'c', 0],\n",
    "                     [12, 19, 306, 59, 5, 'a', 1],\n",
    "                     [12, 19, 306, 59, 5, 'c', 1],\n",
    "                     [13, 18, 298, 55, 3, 'c', 1],\n",
    "                     [20, 20, 250, 70, 5, 'c', 0],\n",
    "                     [21, 20, 254, 68, 4, 'a', 1],\n",
    "                     [21, 20, 254, 68, 4, 'c', 1],\n",
    "                     [22, 19, 244, 70, 3, 'a', 1],\n",
    "                     [30, 27, 264, 78, 4, 'b', 0],\n",
    "                     [31, 22, 293, 67, 4, 'b', 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_df = pd.DataFrame(dmy_data, columns=['subject_id', 'Var0', 'Var1', 'Var2', 'Var3', 'Var4', 'label'])\n",
    "dmy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the columns dtypes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_df['subject_id'] = dmy_df['subject_id'].astype(int)\n",
    "dmy_df['Var0'] = dmy_df['Var0'].astype(int)\n",
    "dmy_df['Var1'] = dmy_df['Var1'].astype(int)\n",
    "dmy_df['Var2'] = dmy_df['Var2'].astype(int)\n",
    "dmy_df['Var3'] = dmy_df['Var3'].astype(int)\n",
    "dmy_df['Var4'] = dmy_df['Var4'].astype(str)\n",
    "dmy_df['label'] = dmy_df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of used features\n",
    "dmy_cols = list(dmy_df.columns)\n",
    "\n",
    "# Remove features that aren't used by the model to predict the label\n",
    "for unused_feature in ['subject_id', 'label']:\n",
    "    dmy_cols.remove(unused_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categories\n",
    "\n",
    "Converting the categorical feature `Var4` into a numeric format, so that it can be used by the neural networks and by embedding layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode each row's categorical value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "dmy_df['Var4'], enum_dict = du.embedding.enum_categorical_feature(dmy_df, feature='Var4')\n",
    "dmy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the rows and their categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_df = du.embedding.join_categorical_enum(dmy_df, cat_feat='Var4', id_columns='subject_id')\n",
    "dmy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "dmy_norm_df = du.data_processing.normalize_data(dmy_df, id_columns='subject_id',\n",
    "                                                categ_columns=['Var4', 'label'], see_progress=False)\n",
    "dmy_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_norm_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting string encodings to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmy_norm_df = du.embedding.string_encod_to_numeric(dmy_norm_df, cat_feat='Var4', inplace=True)\n",
    "dmy_norm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Only run this when testing the MLP, without embeddings\n",
    "# dmy_norm_df = dmy_norm_df.drop(columns='Var4')\n",
    "# dmy_norm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "dataset = Tabular_Dataset(dmy_norm_df.to_numpy(), dmy_norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating into train and validation sets\n",
    "\n",
    "Since this notebook is only for experimentation purposes, with a very small dummy dataset, we'll not be using a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32                                 # Number of patients in a mini batch\n",
    "n_epochs = 50                                   # Number of epochs\n",
    "lr = 0.001                                      # Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separation in train and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and validation sets data loaders, which will allow loading batches\n",
    "train_dataloader, val_dataloader, _ = du.machine_learning.create_train_sets(dataset, test_train_ratio=0, \n",
    "                                                                            validation_ratio=0.25,\n",
    "                                                                            batch_size=4, get_indeces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(val_dataloader))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ids = dmy_norm_df.subject_id.nunique()      # Total number of sequences\n",
    "n_inputs = len(dmy_norm_df.columns)           # Number of input features\n",
    "n_hidden = 10                                 # Number of hidden units\n",
    "n_outputs = 1                                 # Number of outputs\n",
    "n_layers = 2                                  # Number of MLP layers\n",
    "p_dropout = 0.2                               # Probability of dropout\n",
    "use_batch_norm = False                        # Indicates if batch normalization is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Models.MLP(n_inputs-2, n_hidden, n_outputs, n_layers, p_dropout, use_batch_norm)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# Warning: The loss will explode if the feature `Var4` isn't removed or embedded, because of its very high values\n",
    "model = du.deep_learning.train(model, train_dataloader, val_dataloader, cols_to_remove=0,\n",
    "                               model_type='mlp', batch_size=batch_size, n_epochs=n_epochs, \n",
    "                               lr=lr, model_path='models/', do_test=False, log_comet_ml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, metrics = du.deep_learning.model_inference(model, seq_len_dict, dataloader=val_dataloader, \n",
    "                                                   model_type='mlp', metrics=['loss', 'accuracy', 'AUC'],\n",
    "                                                   output_rounded=False, set_name='test', \n",
    "                                                   cols_to_remove=du.search_explore.find_col_idx(dmy_norm_df, 'subject_id'))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP with embedding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ids = dmy_norm_df.subject_id.nunique()      # Total number of sequences\n",
    "n_inputs = len(dmy_norm_df.columns)           # Number of input features\n",
    "n_hidden = 10                                 # Number of hidden units\n",
    "n_outputs = 1                                 # Number of outputs\n",
    "n_layers = 2                                  # Number of LSTM layers\n",
    "p_dropout = 0.2                               # Probability of dropout\n",
    "use_batch_norm = False                        # Indicates if batch normalization is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "model = Models.MLP(n_inputs-2, n_hidden, n_outputs, n_layers, p_dropout, use_batch_norm,\n",
    "                   embed_features=du.search_explore.find_col_idx(dmy_norm_df, 'Var4'), num_embeddings=5,\n",
    "                   embedding_dim=2)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "model = du.deep_learning.train(model, train_dataloader, val_dataloader, cols_to_remove=0,\n",
    "                               model_type='mlp', batch_size=batch_size, n_epochs=n_epochs, \n",
    "                               lr=lr, model_path='models/', do_test=False, log_comet_ml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, metrics = du.deep_learning.model_inference(model, seq_len_dict, dataloader=val_dataloader, \n",
    "                                                   model_type='mlp', metrics=['loss', 'accuracy', 'AUC'],\n",
    "                                                   output_rounded=False, set_name='test', \n",
    "                                                   cols_to_remove=du.search_explore.find_col_idx(dmy_norm_df, 'subject_id'))\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization Learning Network (RLN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "tcga-cancer-classification",
   "language": "python",
   "name": "tcga-cancer-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
